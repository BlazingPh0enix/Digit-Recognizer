# Text-to-Speech (TTS) Application for Reading Digits in Images

This project is a Text-to-Speech (TTS) application that takes an image as input and reads out the digits present in the image. 

## Project Structure

The project consists of the following main components:

1. **train.ipynb**: This Jupyter notebook contains the code for training the model. The model is trained to recognize digits in images.

2. **model.pth**: This file contains the weights of the trained model. It is generated by the `train.ipynb` notebook after the model has been trained.

3. **app.py**: This is the main application file. It loads the trained model from the `model.pth` file and uses it to read digits from input images.

## How to Use

To use this application, follow these steps:

1. Run the `train.ipynb` notebook to train the model and generate the `model.pth` file (Feel free to experiment with different Hyper parameter values so as to get a better accuracy).

2. Run the `app.py` file to start the application.

3. Provide an image as input to the application. The application will read the digits in the image and output them as speech.

## Requirements

This project requires the following libraries:

- PyTorch
- OpenCV
- pyttsx3

These dependencies can be installed using the `requirements.txt` file included in the project. Run the following command in your terminal:

```bash
pip install -r requirements.txt 
```

Please make sure to install these libraries before running the application.